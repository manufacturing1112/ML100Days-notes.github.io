## 龙珠计划-机器学习训练营逻辑回归分类算法基础知识学习笔记
## https://tianchi.aliyun.com/notebook-ai/home#notebookLabId=347088&notebookType=ALL&isHelp=false&operaType=5
### 一、学习知识点概要
#### 1、	逻辑回归的介绍和应用：
①逻辑回归的优缺点；②逻辑回归的应用。
#### 2、学习目标：
①了解 逻辑回归 的理论；②掌握逻辑回归的sklearn函数调用使用并将其运用到鸢尾花的数据集预测。
#### 3、算法实战：
①基于鸢尾花（iris）数据集的逻辑回归分类实践
### 二、学习内容
#### 1、逻辑回归的优缺点：
优点：训练速度较快，分类的时候，计算量只和特征的数目相关；简单易理解； 内存资源占用小，只需要存储各个维度的特征值。
缺点：无法解决非线性问题；难以处理数据不平衡问题；准确率不高，分类精度不高，容易产生欠拟合。
#### 2、逻辑回归的应用：
逻辑回归模型广泛用于各个领域，包括机器学习，大多数医学领域和社会科学。例如，最初由Boyd 等人开发的创伤和损伤严重度评分（TRISS）被广泛用于预测受伤患者的死亡率，使用基于逻辑回归模型观察到的患者特征（年龄，性别，体重指数,各种血液检查的结果等）分析预测发生特定疾病（例如糖尿病，冠心病）的风险。逻辑回归模型也用于预测在给定的过程中，系统或产品的故障的可能性。还用于市场营销应用程序，例如预测客户购买产品或中止订购的倾向等。在经济学中它可以用来预测一个人选择进入劳动力市场的可能性，而商业应用则可以用来预测房主拖欠抵押贷款的可能性。
逻辑回归模型现在同样是很多分类算法的基础组件,比如分类任务中基于GBDT算法+LR逻辑回归实现的信用卡交易反欺诈，CTR(点击通过率)预估等，其好处在于输出值自然地落在0到1之间，并且有概率意义。
#### 3、逻辑回归原理：
利用了Sigmoid函数，函数形式为：
log⁡ⅈ(z)=1/(1+ⅇ^(-z) )
对应图像：
![image](https://user-images.githubusercontent.com/76520773/163116942-6bde8138-7e8d-417c-afc0-dd3de0bbffea.png)
当 z<0时，y<0.5，分类为0；当z>0，y>0.5，分类为1。

#### 4、基于鸢尾花（iris）数据集的逻辑回归分类实践：
#### Step1:库函数导入
①Numpy：处理大量的数组/矩阵运算。

②Pandas：利用Pandas将iris数据转化为DataFrame格式。

③Matplotlib、Seaborn：用于绘图等可视化操作。

④LogisticRegression模型：分类模型。
```Python
//  基础函数库
import numpy as np 
import pandasas pd

// 导入画图库
import matplotlib.pyplot as plt
import seaborn as sns

// 导入逻辑回归模型函数
from sklearn.linear_model import LogisticRegression
```

#### Step2:数据读取/载入
sklearn 中自带iris数据，我们可以利用Pandas转化为DataFrame格式：
```Python
from sklearn.datasets import load_iris
data = load_iris() //得到数据特征
iris_target = data.target //得到数据对应的标签
iris_features = pd.DataFrame(data=data.data, columns=data.feature_names) //利用Pandas转化为DataFrame格式

// 选择其类别为0和1的样本 （不包括类别为2的样本）
X = iris_features.iloc[:100]
Y = iris_target[:100] 
```


#### Step3:将target数据数字化
```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_Y = LabelEncoder()
Y =  labelencoder_Y.fit_transform(Y)
```

#### Step4:拆分数据集为训练集合和测试集合
```python
#from sklearn.model_selection import train_test_split
from sklearn.cross_validation import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 0)
```
#### Step5: 定义和训练逻辑回归模型
```python 
clf = LogisticRegression(random_state=0, solver='lbfgs')
clf = clf.fit(X_train, Y_train)
```

#### Step6:预测结果
```python
// 在训练集和测试集上分布利用训练好的模型进行预测
train_predict = clf.predict(X_train)
test_predict = clf.predict(X_test)

// 由于逻辑回归模型是概率预测模型（前文介绍的 p = p(y=1|x,\theta)）,所有我们可以利用 predict_proba 函数预测其概率
train_predict_proba = clf.predict_proba(x_train)
test_predict_proba = clf.predict_proba(x_test)

print('The test predict Probability of each class:\n',test_predict_proba)
// 其中第一列代表预测为0类的概率，第二列代表预测为1类的概率，第三列代表预测为2类的概率。

// 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_train,train_predict))
print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_test,test_predict))
```
#### Step7:可视化
```python 
// 查看混淆矩阵
confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)
print('The confusion matrix result:\n',confusion_matrix_result)

// 利用热力图对于结果进行可视化
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_result, annot=True, cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()
```
